{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_4708\\1637315564.py:6: DtypeWarning: Columns (0,8,9,10,13,16,18,19,20,21,22,28,29,30) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  merged_data = pd.read_csv(\"./mapped_data/mapped_merged_data.csv\")\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import rc\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "merged_data = pd.read_csv(\"./mapped_data/mapped_merged_data.csv\")\n",
    "\n",
    "\n",
    "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
    "rc('font', family='Malgun Gothic')\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAVEL_ID            98.849432\n",
      "VISIT_AREA_ID        98.849432\n",
      "ACTIVITY_TYPE_CD     98.849432\n",
      "ACTIVITY_TYPE_SEQ    98.849432\n",
      "CONSUME_HIS_SEQ      98.849432\n",
      "CONSUME_HIS_SNO      98.849432\n",
      "PAYMENT_NUM          98.849432\n",
      "BRNO                 99.115745\n",
      "STORE_NM             98.859937\n",
      "ROAD_NM_ADDR         98.977249\n",
      "LOTNO_ADDR           99.293021\n",
      "ROAD_NM_CD           99.071983\n",
      "LOTNO_CD             99.071983\n",
      "PAYMENT_DT           99.036616\n",
      "PAYMENT_MTHD_SE      98.854983\n",
      "PAYMENT_AMT_WON      98.849804\n",
      "PAYMENT_ETC          99.294269\n",
      "SGG_CD                0.000000\n",
      "POI_ID                1.150568\n",
      "POI_NM                1.150634\n",
      "BRNO_POI              1.150568\n",
      "ROAD_NM_ADDR_POI     15.394293\n",
      "LOTNO_ADDR_POI        1.150568\n",
      "ASORT_LCLASDC        87.585680\n",
      "ASORT_MLSFCDC        87.585680\n",
      "ASORT_SDASDC         87.585680\n",
      "X_COORD               1.150568\n",
      "Y_COORD               1.150568\n",
      "ROAD_NM_CD_POI        1.150568\n",
      "LOTNO_CD_POI          1.150568\n",
      "region                8.583069\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "missing_ratio = merged_data.isnull().sum() / len(merged_data) * 100\n",
    "print(missing_ratio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ í•œê¸€ ì§€ì—­ëª…ì„ ì˜ì–´ë¡œ ë³€í™˜í•˜ëŠ” ë§¤í•‘ ë”•ì…”ë„ˆë¦¬\n",
    "region_mapping = {\n",
    "    \"ì„œìš¸íŠ¹ë³„ì‹œ\": \"Seoul\",\n",
    "    \"ë¶€ì‚°ê´‘ì—­ì‹œ\": \"Busan\",\n",
    "    \"ëŒ€êµ¬ê´‘ì—­ì‹œ\": \"Daegu\",\n",
    "    \"ì¸ì²œê´‘ì—­ì‹œ\": \"Incheon\",\n",
    "    \"ê´‘ì£¼ê´‘ì—­ì‹œ\": \"Gwangju\",\n",
    "    \"ëŒ€ì „ê´‘ì—­ì‹œ\": \"Daejeon\",\n",
    "    \"ìš¸ì‚°ê´‘ì—­ì‹œ\": \"Ulsan\",\n",
    "    \"ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ\": \"Sejong\",\n",
    "    \"ê²½ê¸°ë„\": \"Gyeonggi\",\n",
    "    \"ê°•ì›ë„\": \"Gangwon\",\n",
    "    \"ì¶©ì²­ë¶ë„\": \"Chungbuk\",\n",
    "    \"ì¶©ì²­ë‚¨ë„\": \"Chungnam\",\n",
    "    \"ì „ë¼ë¶ë„\": \"Jeonbuk\",\n",
    "    \"ì „ë¼ë‚¨ë„\": \"Jeonnam\",\n",
    "    \"ê²½ìƒë¶ë„\": \"Gyeongbuk\",\n",
    "    \"ê²½ìƒë‚¨ë„\": \"Gyeongnam\",\n",
    "    \"ì œì£¼íŠ¹ë³„ìì¹˜ë„\": \"Jeju\"\n",
    "}\n",
    "\n",
    "# 2ï¸âƒ£ ì§€ì—­ëª…ì„ ì˜ì–´ë¡œ ë³€í™˜\n",
    "merged_data[\"region\"] = merged_data[\"region\"].map(region_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TRAVEL_ID            0\n",
       "VISIT_AREA_ID        0\n",
       "ACTIVITY_TYPE_CD     0\n",
       "ACTIVITY_TYPE_SEQ    0\n",
       "CONSUME_HIS_SEQ      0\n",
       "CONSUME_HIS_SNO      0\n",
       "PAYMENT_NUM          0\n",
       "BRNO                 0\n",
       "STORE_NM             0\n",
       "ROAD_NM_ADDR         0\n",
       "LOTNO_ADDR           0\n",
       "ROAD_NM_CD           0\n",
       "LOTNO_CD             0\n",
       "PAYMENT_DT           0\n",
       "PAYMENT_MTHD_SE      0\n",
       "PAYMENT_AMT_WON      0\n",
       "PAYMENT_ETC          0\n",
       "SGG_CD               0\n",
       "POI_ID               0\n",
       "POI_NM               0\n",
       "BRNO_POI             0\n",
       "ROAD_NM_ADDR_POI     0\n",
       "LOTNO_ADDR_POI       0\n",
       "ASORT_LCLASDC        0\n",
       "ASORT_MLSFCDC        0\n",
       "ASORT_SDASDC         0\n",
       "X_COORD              0\n",
       "Y_COORD              0\n",
       "ROAD_NM_CD_POI       0\n",
       "LOTNO_CD_POI         0\n",
       "region               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ğŸš¨ ë²”ì£¼í˜• ë³€ìˆ˜ ëª©ë¡\n",
    "categorical_features = [\n",
    "    \"TRAVEL_ID\", \"STORE_NM\", \"ROAD_NM_ADDR\", \"LOTNO_ADDR\", \"PAYMENT_DT\",\n",
    "    \"PAYMENT_ETC\", \"POI_ID\", \"POI_NM\", \"BRNO_POI\", \"ROAD_NM_ADDR_POI\",\n",
    "    \"LOTNO_ADDR_POI\", \"ROAD_NM_CD_POI\", \"LOTNO_CD_POI\"\n",
    "]\n",
    "\n",
    "\n",
    "# ğŸš¨ ë²”ì£¼í˜• ë³€ìˆ˜: ìµœë¹ˆê°’(Mode) ë˜ëŠ” \"Missing\" ì¹´í…Œê³ ë¦¬ ì¶”ê°€\n",
    "for col in categorical_features:\n",
    "    mode_value = merged_data[col].mode()[0] if not merged_data[col].mode().empty else \"Missing\"\n",
    "    merged_data[col] = merged_data[col].fillna(mode_value)\n",
    "\n",
    "\n",
    "# ğŸš¨ ìˆ˜ì¹˜í˜•(float64) ë³€ìˆ˜ ì¤‘ ê²°ì¸¡ì¹˜ê°€ ìˆëŠ” ë³€ìˆ˜ ì°¾ê¸°\n",
    "numeric_cols_with_nan = merged_data.select_dtypes(include=['float64']).columns\n",
    "\n",
    "# ğŸš¨ í•´ë‹¹ ë³€ìˆ˜ë“¤ì˜ ê²°ì¸¡ì¹˜ë¥¼ **ì¤‘ì•™ê°’(Median)**ìœ¼ë¡œ ëŒ€ì²´\n",
    "for col in numeric_cols_with_nan:\n",
    "    median_value = merged_data[col].median()  # ì¤‘ì•™ê°’ ê³„ì‚°\n",
    "    merged_data[col].fillna(median_value)\n",
    "\n",
    "# ğŸš¨ 'region'ì˜ NaN ê°’ ì œê±°\n",
    "merged_data = merged_data.dropna(subset=[\"region\"])\n",
    "\n",
    "\n",
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”¹ Processing Binary Classification for Seoul vs Others\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Encoders require their input argument must be uniformly strings or numbers. Got ['float', 'str']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\travel\\Lib\\site-packages\\sklearn\\utils\\_encode.py:174\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    172\u001b[0m uniques_set, missing_values \u001b[38;5;241m=\u001b[39m _extract_missing(uniques_set)\n\u001b[1;32m--> 174\u001b[0m uniques \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43muniques_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    175\u001b[0m uniques\u001b[38;5;241m.\u001b[39mextend(missing_values\u001b[38;5;241m.\u001b[39mto_list())\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'float'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m categorical_cols:\n\u001b[0;32m     50\u001b[0m     le \u001b[38;5;241m=\u001b[39m LabelEncoder()\n\u001b[1;32m---> 51\u001b[0m     X[col] \u001b[38;5;241m=\u001b[39m \u001b[43mle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# âœ… ë°ì´í„° ë¶„í•  (Train / Test)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, stratify\u001b[38;5;241m=\u001b[39my)\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\travel\\Lib\\site-packages\\sklearn\\preprocessing\\_label.py:115\u001b[0m, in \u001b[0;36mLabelEncoder.fit_transform\u001b[1;34m(self, y)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit label encoder and return encoded labels.\u001b[39;00m\n\u001b[0;32m    103\u001b[0m \n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Encoded labels.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    114\u001b[0m y \u001b[38;5;241m=\u001b[39m column_or_1d(y, warn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m--> 115\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_, y \u001b[38;5;241m=\u001b[39m \u001b[43m_unique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m y\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\travel\\Lib\\site-packages\\sklearn\\utils\\_encode.py:42\u001b[0m, in \u001b[0;36m_unique\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to find unique values with support for python objects.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03mUses pure python method for object dtype, and numpy method for\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    array. Only provided if `return_counts` is True.\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_unique_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_counts\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# numerical\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _unique_np(\n\u001b[0;32m     47\u001b[0m     values, return_inverse\u001b[38;5;241m=\u001b[39mreturn_inverse, return_counts\u001b[38;5;241m=\u001b[39mreturn_counts\n\u001b[0;32m     48\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\anaconda3\\envs\\travel\\Lib\\site-packages\\sklearn\\utils\\_encode.py:179\u001b[0m, in \u001b[0;36m_unique_python\u001b[1;34m(values, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    178\u001b[0m     types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(t\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mset\u001b[39m(\u001b[38;5;28mtype\u001b[39m(v) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m values))\n\u001b[1;32m--> 179\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    180\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncoders require their input argument must be uniformly \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    181\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrings or numbers. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    182\u001b[0m     )\n\u001b[0;32m    183\u001b[0m ret \u001b[38;5;241m=\u001b[39m (uniques,)\n\u001b[0;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_inverse:\n",
      "\u001b[1;31mTypeError\u001b[0m: Encoders require their input argument must be uniformly strings or numbers. Got ['float', 'str']"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, roc_curve, confusion_matrix, auc\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# âœ… Bootstrappingì„ ì´ìš©í•œ AUC ì‹ ë¢° êµ¬ê°„ ê³„ì‚° í•¨ìˆ˜\n",
    "def bootstrap_auc_ci(y_true, y_pred_proba, n_bootstraps=1000, alpha=0.95):\n",
    "    \"\"\"\n",
    "    Bootstrappingì„ ì´ìš©í•˜ì—¬ ROC AUCì˜ 95% ì‹ ë¢° êµ¬ê°„ì„ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "    \"\"\"\n",
    "    bootstrapped_scores = []\n",
    "\n",
    "    for _ in range(n_bootstraps):\n",
    "        # ëœë¤ ìƒ˜í”Œë§\n",
    "        indices = np.random.choice(len(y_true), len(y_true), replace=True)\n",
    "        if len(np.unique(y_true[indices])) < 2:\n",
    "            continue  # AUCë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ëŠ” ê²½ìš° ë¬´ì‹œ\n",
    "        score = roc_auc_score(y_true[indices], y_pred_proba[indices])\n",
    "        bootstrapped_scores.append(score)\n",
    "\n",
    "    # ì‹ ë¢° êµ¬ê°„ ê³„ì‚°\n",
    "    lower_bound = np.percentile(bootstrapped_scores, ((1.0 - alpha) / 2) * 100)\n",
    "    upper_bound = np.percentile(bootstrapped_scores, (alpha + ((1.0 - alpha) / 2)) * 100)\n",
    "    \n",
    "    return np.mean(bootstrapped_scores), lower_bound, upper_bound\n",
    "\n",
    "\n",
    "# âœ… ëª¨ë“  ì§€ì—­ì„ One-vs-Rest ë°©ì‹ìœ¼ë¡œ ì´ì§„ ë¶„ë¥˜\n",
    "unique_regions = merged_data[\"region\"].unique()\n",
    "final_results = []\n",
    "\n",
    "for region in unique_regions:\n",
    "    print(f\"\\nğŸ”¹ Processing Binary Classification for {region} vs Others\")\n",
    "\n",
    "    # âœ… íŠ¹ì„±(X)ê³¼ íƒ€ê²Ÿ(y) ì„¤ì • (ê° ì§€ì—­ vs ë‚˜ë¨¸ì§€)\n",
    "    X = merged_data.drop(columns=[\"region\"])  # ì…ë ¥ ë³€ìˆ˜\n",
    "    y = merged_data[\"region\"].apply(lambda x: 1 if x == region else 0)  # í˜„ì¬ ì§€ì—­ì„ 1, ë‚˜ë¨¸ì§€ë¥¼ 0ìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "   # âœ… ë²”ì£¼í˜• ë³€ìˆ˜ ì²˜ë¦¬ (Label Encoding)\n",
    "    categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "    for col in categorical_cols:\n",
    "        X[col] = X[col].astype(str)  # ëª¨ë“  ê°’ì„ ë¬¸ìì—´(str)ë¡œ ë³€í™˜\n",
    "        le = LabelEncoder()\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "\n",
    "    # âœ… ë°ì´í„° ë¶„í•  (Train / Test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # âœ… ëª¨ë¸ ì •ì˜\n",
    "    models = {\n",
    "        \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "        \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "        \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42),\n",
    "        \"LightGBM\": LGBMClassifier(random_state=42),\n",
    "        \"CatBoost\": CatBoostClassifier(verbose=0, random_state=42)\n",
    "    }\n",
    "\n",
    "    # âœ… ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
    "    results = []\n",
    "    conf_matrices = {}\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]  # í™•ë¥ ê°’\n",
    "        \n",
    "        # ROC AUC ë° 95% CI ê³„ì‚°\n",
    "        mean_auc, lower_ci, upper_ci = bootstrap_auc_ci(y_test.to_numpy(), y_pred_proba)\n",
    " \n",
    "        # Precision-Recall Curve ê³„ì‚°\n",
    "        precision, recall, _ = precision_recall_curve(y_test, y_pred_proba)\n",
    "        pr_auc = auc(recall, precision)\n",
    "\n",
    "        # Confusion Matrix ì €ì¥\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        conf_matrices[model_name] = conf_matrix\n",
    "\n",
    "        # ê²°ê³¼ ì €ì¥\n",
    "        results.append([region, model_name, mean_auc, lower_ci, upper_ci, pr_auc])\n",
    "\n",
    "    # âœ… ì§€ì—­ë³„ ê²°ê³¼ ì €ì¥\n",
    "    results_df = pd.DataFrame(results, columns=[\"Region\", \"Model\", \"ROC AUC\", \"ROC AUC Lower CI\", \"ROC AUC Upper CI\", \"PR AUC\"])\n",
    "    final_results.append(results_df)\n",
    "\n",
    "# âœ… ëª¨ë“  ì§€ì—­ ê²°ê³¼ í•©ì¹˜ê¸°\n",
    "final_results_df = pd.concat(final_results, ignore_index=True)\n",
    "\n",
    "# âœ… ê²°ê³¼ë¥¼ Excel íŒŒì¼ë¡œ ì €ì¥\n",
    "excel_filename = \"./binary_classification_results.xlsx\"\n",
    "final_results_df.to_excel(excel_filename, index=False)\n",
    "\n",
    "\n",
    "# âœ… ê²°ê³¼ ì¶œë ¥\n",
    "import ace_tools_open as tools\n",
    "tools.display_dataframe_to_user(name=\"Binary Classification Results (Each Region vs Others)\", dataframe=final_results_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
